{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build 3D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "m = 60\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X = np.empty((m, 3))\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manually Projection PCA\n",
    "\n",
    "    find d priciple vectors with most variance (if map data on it) and then transform data on new space\n",
    "    use svd to find vectors with mathematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)\n",
    "U, s, Vt = np.linalg.svd(X_centered)\n",
    "c1 = Vt.T[:, 0]\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "S = np.zeros(X_centered.shape)\n",
    "S[:n, :n] = np.diag(s) # qotri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.77645005, 0.        , 0.        ],\n",
       "       [0.        , 2.82403671, 0.        ],\n",
       "       [0.        , 0.        , 0.78116597],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X_centered, U.dot(S).dot(Vt))\n",
    "# Returns True if two arrays are element-wise equal within a tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]\n",
    "X2D = X_centered.dot(W2)\n",
    "X2D_using_svd = X2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA  using scikit learn\n",
    "takes care of mean centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "# find PCs\n",
    "# transford them\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26203346,  0.42067648],\n",
       "       [-0.08001485, -0.35272239],\n",
       "       [ 1.17545763,  0.36085729],\n",
       "       [ 0.89305601, -0.30862856],\n",
       "       [ 0.73016287, -0.25404049]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2D[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26203346, -0.42067648],\n",
       "       [ 0.08001485,  0.35272239],\n",
       "       [-1.17545763, -0.36085729],\n",
       "       [-0.89305601,  0.30862856],\n",
       "       [-0.73016287,  0.25404049]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2D_using_svd[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if train severall time it may have different Principle Components. in general difference is that they just flipped(negative of each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X2D, X2D_using_svd), np.allclose(X2D, -X2D_using_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the 3D points projected on the plane (PCA 2D subspace)\n",
    "\n",
    "X3D_inv = pca.inverse_transform(X2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there was some loss of information during the projection step\n",
    "so the recovered 3D points are not exactly equal to the original 3D points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X, X3D_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010170337792848549"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruction error\n",
    "\n",
    "np.mean(np.sum(np.square(X3D_inv - X) , axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3D_inv_using_svd = X2D_using_svd.dot(Vt[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn tack care of mean and reversing it\n",
    "\n",
    "np.allclose(X3D_inv_using_svd, X3D_inv - pca.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02406745, 0.20932515, 0.07155422])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93636116, -0.29854881, -0.18465208],\n",
       "       [ 0.34027485, -0.90119108, -0.2684542 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#principle components\n",
    "\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93636116,  0.29854881,  0.18465208],\n",
       "       [-0.34027485,  0.90119108,  0.2684542 ],\n",
       "       [-0.08626012, -0.31420255,  0.94542898]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# principle componets manually\n",
    "\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84248607, 0.14631839])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explained variance: portion of dataset's variance for each PC\n",
    "\n",
    "pca.explained_variance_ratio_\n",
    "# only 1.1% remain for 3th PC so we lost little information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84248607, 0.14631839, 0.01119554])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  compute the explained variance ratio using the SVD approach (recall that s is the diagonal of the matrix S)\n",
    "\n",
    "np.square(s)/np.square(s).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chosing Number for dimention reduction\n",
    "#### 2d or 3d for visualization, more than threshold for variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.target = mnist.target.astype(np.uint8)\n",
    "\n",
    "# split train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.09719832, 0.16875148, 0.23046024, 0.28447767, 0.33353621,\n",
       "        0.37656401, 0.40934646, 0.43819275, 0.46567853, 0.48924485,\n",
       "        0.51032629, 0.5307285 , 0.54778858, 0.56465048, 0.58041792,\n",
       "        0.59534958, 0.60862878, 0.62147783, 0.63334578, 0.64479193,\n",
       "        0.65545804, 0.66555448, 0.67514241, 0.68416896, 0.69296211,\n",
       "        0.70131513, 0.70939893, 0.71727437, 0.72468736, 0.73157212,\n",
       "        0.73812949, 0.74459959, 0.75058197, 0.75643475, 0.76210811,\n",
       "        0.7675608 , 0.77261474, 0.77750626, 0.78230885, 0.78696883,\n",
       "        0.79152081, 0.79597374, 0.80014325, 0.80411726, 0.80795962,\n",
       "        0.81171266, 0.81533146, 0.81882001, 0.8221978 , 0.82541301,\n",
       "        0.82859763, 0.83168676, 0.83465474, 0.83752128, 0.84034773,\n",
       "        0.84303834, 0.84571815, 0.84828932, 0.85083357, 0.85329543,\n",
       "        0.85569464, 0.8580644 , 0.86035289, 0.86256245, 0.86468703,\n",
       "        0.86673787, 0.86875875, 0.87071732, 0.87263867, 0.87451472,\n",
       "        0.87637902, 0.87817437, 0.87993644, 0.88167564, 0.88332694,\n",
       "        0.88496271, 0.88657643, 0.88811577, 0.88959381, 0.89101268,\n",
       "        0.89242922, 0.89382729, 0.89522047, 0.8965766 , 0.89790212,\n",
       "        0.89922092, 0.90051436, 0.90177067, 0.90299961, 0.90420227,\n",
       "        0.90536827, 0.90651236, 0.90763806, 0.90874186, 0.90983388,\n",
       "        0.9109034 , 0.91194418, 0.91297678, 0.91397927, 0.91497747,\n",
       "        0.9159598 , 0.91690149, 0.91783568, 0.91874693, 0.9196482 ,\n",
       "        0.92054264, 0.92140428, 0.92225451, 0.92309577, 0.92391214,\n",
       "        0.92470134, 0.92547689, 0.92625005, 0.92701393, 0.92777534,\n",
       "        0.92851944, 0.92925313, 0.92997872, 0.93069175, 0.93139362,\n",
       "        0.93208928, 0.9327773 , 0.93345445, 0.93412851, 0.9347898 ,\n",
       "        0.93543203, 0.93606826, 0.93669991, 0.93731862, 0.93792105,\n",
       "        0.93852032, 0.93911772, 0.93970653, 0.94028677, 0.94086469,\n",
       "        0.94143457, 0.94199662, 0.94254513, 0.94308037, 0.94360648,\n",
       "        0.94412851, 0.94463613, 0.94513923, 0.94563826, 0.94613531,\n",
       "        0.94662917, 0.9471147 , 0.94759725, 0.9480685 , 0.94853659,\n",
       "        0.94900033, 0.94946166, 0.94991842, 0.95036844, 0.95081565,\n",
       "        0.95125944, 0.95169671, 0.95212409, 0.95254411, 0.95296244,\n",
       "        0.9533741 , 0.95378237, 0.95418269, 0.95457805, 0.95496992,\n",
       "        0.9553597 , 0.95574301, 0.95612161, 0.9564982 , 0.95687068,\n",
       "        0.95723707, 0.95760027, 0.95796286, 0.95832109, 0.95867489,\n",
       "        0.95902729, 0.95937418, 0.95971865, 0.96006129, 0.96039856,\n",
       "        0.96073368, 0.96106288, 0.96138943, 0.96171387, 0.96203501,\n",
       "        0.96235523, 0.96267089, 0.96298439, 0.96329457, 0.96360151,\n",
       "        0.96390714, 0.96421066, 0.96451167, 0.96481186, 0.96510904,\n",
       "        0.96540335, 0.96569561, 0.96598681, 0.96627457, 0.96655928,\n",
       "        0.96684207, 0.96712034, 0.96739511, 0.96766553, 0.96793427,\n",
       "        0.96820115, 0.96846617, 0.96872934, 0.96899048, 0.96924982,\n",
       "        0.969508  , 0.9697641 , 0.9700187 , 0.97027163, 0.97052358,\n",
       "        0.97077293, 0.97102026, 0.97126555, 0.9715084 , 0.97175004,\n",
       "        0.97199051, 0.97222924, 0.97246637, 0.97270104, 0.97293287,\n",
       "        0.97316365, 0.97339438, 0.97362278, 0.9738499 , 0.97407402,\n",
       "        0.97429539, 0.97451557, 0.97473531, 0.97495241, 0.97516712,\n",
       "        0.9753797 , 0.97559206, 0.9758017 , 0.97601081, 0.97621875,\n",
       "        0.97642424, 0.97662683, 0.9768281 , 0.97702854, 0.9772268 ,\n",
       "        0.97742402, 0.97761958, 0.97781336, 0.97800674, 0.97819873,\n",
       "        0.97838955, 0.97857832, 0.97876568, 0.97895226, 0.97913858,\n",
       "        0.97932348, 0.97950696, 0.97968875, 0.97987028, 0.98005059,\n",
       "        0.98022851, 0.98040472, 0.98057947, 0.98075307, 0.9809259 ,\n",
       "        0.98109819, 0.98126892, 0.98143933, 0.9816082 , 0.98177628,\n",
       "        0.9819434 , 0.98210892, 0.98227286, 0.98243546, 0.98259722,\n",
       "        0.98275827, 0.98291864, 0.98307788, 0.98323709, 0.98339502,\n",
       "        0.98355127, 0.98370638, 0.98386028, 0.98401377, 0.98416508,\n",
       "        0.984315  , 0.98446428, 0.98461175, 0.98475905, 0.9849048 ,\n",
       "        0.98504911, 0.98519183, 0.98533399, 0.98547554, 0.98561655,\n",
       "        0.98575678, 0.98589473, 0.98603236, 0.98616894, 0.98630493,\n",
       "        0.98643978, 0.98657362, 0.98670677, 0.98683906, 0.98696962,\n",
       "        0.98709868, 0.98722672, 0.98735431, 0.98748084, 0.98760728,\n",
       "        0.98773316, 0.98785848, 0.98798297, 0.9881065 , 0.98822836,\n",
       "        0.98834968, 0.98846973, 0.9885889 , 0.98870762, 0.98882572,\n",
       "        0.98894243, 0.98905877, 0.98917495, 0.98929021, 0.98940457,\n",
       "        0.98951846, 0.98963079, 0.98974208, 0.98985258, 0.98996229,\n",
       "        0.99007131, 0.99018007, 0.9902879 , 0.99039489, 0.99050134,\n",
       "        0.99060741, 0.99071345, 0.99081818, 0.99092154, 0.99102383,\n",
       "        0.99112502, 0.9912259 , 0.99132595, 0.99142524, 0.99152447,\n",
       "        0.99162273, 0.99172049, 0.99181732, 0.99191256, 0.99200678,\n",
       "        0.99210082, 0.99219387, 0.9922857 , 0.99237699, 0.99246821,\n",
       "        0.99255816, 0.99264772, 0.99273682, 0.9928251 , 0.99291217,\n",
       "        0.99299887, 0.99308492, 0.99317032, 0.99325523, 0.99333955,\n",
       "        0.99342333, 0.99350604, 0.99358839, 0.99367043, 0.99375151,\n",
       "        0.99383202, 0.99391198, 0.99399116, 0.9940692 , 0.99414684,\n",
       "        0.99422404, 0.99430025, 0.99437565, 0.99445022, 0.99452425,\n",
       "        0.99459715, 0.99466955, 0.99474154, 0.99481294, 0.99488378,\n",
       "        0.99495376, 0.9950232 , 0.99509214, 0.99515953, 0.99522681,\n",
       "        0.99529301, 0.99535842, 0.99542312, 0.99548711, 0.99555032,\n",
       "        0.99561299, 0.99567446, 0.99573557, 0.99579554, 0.99585539,\n",
       "        0.99591429, 0.99597272, 0.99603058, 0.99608815, 0.99614453,\n",
       "        0.99620069, 0.99625618, 0.99631098, 0.99636529, 0.99641929,\n",
       "        0.99647212, 0.9965248 , 0.99657712, 0.9966289 , 0.99668024,\n",
       "        0.99673134, 0.99678131, 0.99683026, 0.99687909, 0.9969273 ,\n",
       "        0.99697489, 0.99702183, 0.99706829, 0.99711436, 0.99715952,\n",
       "        0.99720397, 0.99724733, 0.9972896 , 0.99733172, 0.99737343,\n",
       "        0.99741513, 0.9974564 , 0.99749694, 0.99753724, 0.99757726,\n",
       "        0.99761601, 0.99765422, 0.99769228, 0.99772964, 0.99776646,\n",
       "        0.99780309, 0.99783946, 0.99787492, 0.99791016, 0.99794503,\n",
       "        0.99797957, 0.99801388, 0.99804796, 0.99808056, 0.99811297,\n",
       "        0.9981451 , 0.99817683, 0.9982082 , 0.99823919, 0.99826903,\n",
       "        0.99829883, 0.9983281 , 0.99835714, 0.99838613, 0.99841416,\n",
       "        0.99844208, 0.99846954, 0.99849649, 0.99852313, 0.99854878,\n",
       "        0.99857388, 0.99859886, 0.99862357, 0.99864806, 0.99867243,\n",
       "        0.99869648, 0.99872032, 0.99874404, 0.99876744, 0.99879048,\n",
       "        0.99881267, 0.9988345 , 0.99885608, 0.99887749, 0.99889864,\n",
       "        0.99891916, 0.99893952, 0.99895978, 0.99897981, 0.99899946,\n",
       "        0.99901888, 0.9990381 , 0.99905721, 0.99907557, 0.9990937 ,\n",
       "        0.99911153, 0.99912922, 0.99914654, 0.99916358, 0.99917999,\n",
       "        0.99919613, 0.99921205, 0.99922778, 0.99924315, 0.9992583 ,\n",
       "        0.99927306, 0.99928772, 0.99930234, 0.99931682, 0.99933089,\n",
       "        0.99934469, 0.99935833, 0.99937185, 0.99938527, 0.99939863,\n",
       "        0.99941127, 0.99942374, 0.99943595, 0.99944804, 0.99946005,\n",
       "        0.99947194, 0.99948361, 0.99949519, 0.99950668, 0.99951806,\n",
       "        0.99952915, 0.99954015, 0.99955084, 0.99956134, 0.99957163,\n",
       "        0.99958178, 0.99959178, 0.99960108, 0.99961025, 0.99961928,\n",
       "        0.99962827, 0.9996371 , 0.99964575, 0.99965396, 0.99966212,\n",
       "        0.9996701 , 0.99967789, 0.9996856 , 0.99969319, 0.99970074,\n",
       "        0.99970822, 0.99971566, 0.99972297, 0.99973022, 0.99973738,\n",
       "        0.99974449, 0.99975131, 0.99975796, 0.99976453, 0.99977098,\n",
       "        0.99977683, 0.99978254, 0.99978813, 0.9997937 , 0.99979917,\n",
       "        0.99980458, 0.9998099 , 0.99981519, 0.99982026, 0.9998251 ,\n",
       "        0.99982993, 0.99983476, 0.99983935, 0.99984388, 0.99984835,\n",
       "        0.99985278, 0.99985699, 0.99986112, 0.99986511, 0.9998691 ,\n",
       "        0.99987306, 0.99987678, 0.99988033, 0.99988386, 0.99988722,\n",
       "        0.99989054, 0.99989383, 0.99989712, 0.99990034, 0.99990348,\n",
       "        0.99990655, 0.99990948, 0.99991231, 0.99991507, 0.99991781,\n",
       "        0.99992045, 0.99992286, 0.99992525, 0.99992763, 0.99992989,\n",
       "        0.99993209, 0.99993424, 0.99993637, 0.99993848, 0.9999405 ,\n",
       "        0.99994245, 0.99994433, 0.9999462 , 0.99994801, 0.99994981,\n",
       "        0.99995156, 0.9999533 , 0.99995494, 0.99995657, 0.99995819,\n",
       "        0.99995978, 0.9999613 , 0.99996263, 0.99996394, 0.99996523,\n",
       "        0.9999665 , 0.99996776, 0.99996896, 0.99997012, 0.99997126,\n",
       "        0.99997237, 0.99997345, 0.99997451, 0.99997555, 0.99997653,\n",
       "        0.99997748, 0.99997841, 0.99997932, 0.99998018, 0.99998103,\n",
       "        0.99998185, 0.99998267, 0.99998347, 0.99998422, 0.99998496,\n",
       "        0.99998567, 0.99998636, 0.99998703, 0.9999877 , 0.99998832,\n",
       "        0.99998892, 0.99998947, 0.99999   , 0.99999046, 0.99999092,\n",
       "        0.99999138, 0.99999182, 0.99999222, 0.9999926 , 0.99999299,\n",
       "        0.99999335, 0.99999371, 0.99999405, 0.99999438, 0.99999471,\n",
       "        0.99999503, 0.99999533, 0.99999562, 0.99999588, 0.99999613,\n",
       "        0.99999637, 0.99999659, 0.99999682, 0.99999704, 0.99999725,\n",
       "        0.99999746, 0.99999766, 0.99999785, 0.999998  , 0.99999816,\n",
       "        0.9999983 , 0.99999843, 0.99999856, 0.99999867, 0.99999878,\n",
       "        0.99999889, 0.99999899, 0.99999909, 0.99999918, 0.99999926,\n",
       "        0.99999935, 0.99999943, 0.99999949, 0.99999954, 0.9999996 ,\n",
       "        0.99999965, 0.99999969, 0.99999972, 0.99999976, 0.99999979,\n",
       "        0.99999981, 0.99999983, 0.99999985, 0.99999986, 0.99999988,\n",
       "        0.9999999 , 0.99999991, 0.99999993, 0.99999994, 0.99999995,\n",
       "        0.99999996, 0.99999997, 0.99999997, 0.99999998, 0.99999998,\n",
       "        0.99999999, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 153,\n",
       " 154)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) # accumulated sum of prev elements on each column\n",
    "\n",
    "# 1. can set d \n",
    "d = np.argmax(cumsum >=0.95) +1\n",
    "\n",
    "\n",
    "\n",
    "cumsum, np.argmax(cumsum >=0.95) , d # 784 ==> 154 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. can set ncomponents as a ration of varianace\n",
    "pca = PCA(n_components = 0.95)\n",
    "X_reduce = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 154)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "X_recovered = pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized PCA\n",
    "#### y finds an approximation of the first d principal components\n",
    "#### svd_solver to randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components=154, svd_solver=\"randomized\")\n",
    "X_reduced = rnd_pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental PCA\n",
    "#### split TS into mini-batches --> good for PCA online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n_batches = 100\n",
    "\n",
    "inc_pca = IncrementalPCA(n_components = 154)\n",
    "\n",
    "for X_batch in np.array_split(X_train, n_batches): # array .split\n",
    "   inc_pca.partial_fit(X_batch)  # partial_fit\n",
    "\n",
    "X_reduce = inc_pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using memmap\n",
    "\n",
    "#### stored in a binary file on disk as if it were entirely in memory\n",
    "#### loads only the data it needs in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_mnist.data\"\n",
    "m, n = X_train.shape\n",
    "\n",
    "X_mm = np.memmap(filename, dtype='float32', mode='write', shape=(m, n))\n",
    "X_mm[:] = X_train\n",
    " \n",
    "#Now deleting the memmap() object will trigger its Python finalizer, which ensures that the data is saved to disk    \n",
    "del X_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncrementalPCA(batch_size=525, n_components=154)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mm = np.memmap(filename, dtype=\"float32\", mode=\"readonly\", shape=(m, n))\n",
    "\n",
    "batch_size = m // n_batches\n",
    "inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
    "inc_pca.fit(X_mm)  # fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components = 2\n",
      "    PCA: 2.5 seconds\n",
      "    IncrementalPCA: 66.2 seconds\n",
      "    PCA: 3.9 seconds\n",
      "n_components = 10\n",
      "    PCA: 6.6 seconds\n",
      "    IncrementalPCA: 78.6 seconds\n",
      "    PCA: 3.4 seconds\n",
      "n_components = 154\n",
      "    PCA: 25.2 seconds\n",
      "    IncrementalPCA: 120.4 seconds\n",
      "    PCA: 25.5 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for n_components in (2, 10, 154):\n",
    "    print(\"n_components =\", n_components)\n",
    "    regular_pca = PCA(n_components=n_components)\n",
    "    inc_pca = IncrementalPCA(n_components=n_components, batch_size=500)\n",
    "    rnd_pca = PCA(n_components=n_components, random_state=42, svd_solver=\"randomized\")\n",
    "\n",
    "    for pca in (regular_pca, inc_pca, rnd_pca):\n",
    "        t1 = time.time()\n",
    "        pca.fit(X_train)\n",
    "        t2 = time.time()\n",
    "        print(\"    {}: {:.1f} seconds\".format(pca.__class__.__name__, t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different size of instances : pca vs random pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rpca = []\n",
    "times_pca = []\n",
    "sizes = [1000, 10000, 20000, 30000, 40000, 50000, 70000, 100000, 200000, 500000]\n",
    "for n_samples in sizes:\n",
    "    X = np.random.randn(n_samples, 5)\n",
    "    pca = PCA(n_components = 2, svd_solver=\"randomized\", random_state=42)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_rpca.append(t2 - t1)\n",
    "    pca = PCA(n_components = 2)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_pca.append(t2 - t1)\n",
    "\n",
    "plt.plot(sizes, times_rpca, \"b-o\", label=\"RPCA\")\n",
    "plt.plot(sizes, times_pca, \"r-s\", label=\"PCA\")\n",
    "plt.xlabel(\"n_samples\")\n",
    "plt.ylabel(\"Training time\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"PCA and Randomized PCA time complexity \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### various feature performance: pca vs random pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rpca = []\n",
    "times_pca = []\n",
    "sizes = [1000, 2000, 3000, 4000, 5000, 6000]\n",
    "for n_features in sizes:\n",
    "    X = np.random.randn(2000, n_features)\n",
    "    pca = PCA(n_components = 2, random_state=42, svd_solver=\"randomized\")\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_rpca.append(t2 - t1)\n",
    "    pca = PCA(n_components = 2)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_pca.append(t2 - t1)\n",
    "\n",
    "plt.plot(sizes, times_rpca, \"b-o\", label=\"RPCA\")\n",
    "plt.plot(sizes, times_pca, \"r-s\", label=\"PCA\")\n",
    "plt.xlabel(\"n_features\")\n",
    "plt.ylabel(\"Training time\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"PCA and Randomized PCA time complexity \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('kpca', KernelPCA(n_components=2)),\n",
       "                                       ('log_reg', LogisticRegression())]),\n",
       "             param_grid=[{'kpca__gamma': array([0.03      , 0.03222222, 0.03444444, 0.03666667, 0.03888889,\n",
       "       0.04111111, 0.04333333, 0.04555556, 0.04777778, 0.05      ]),\n",
       "                          'kpca__kernel': ['rbf', 'sigmoid']}])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which kernel?\n",
    "\n",
    "# 1.grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "y = t > 6.9\n",
    "\n",
    "clf = Pipeline([\n",
    "        (\"kpca\", KernelPCA(n_components=2)),\n",
    "        (\"log_reg\", LogisticRegression(solver=\"lbfgs\"))\n",
    "    ])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "        \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. reconstruction error\n",
    "\n",
    "## use pre-image error for kernels instead of square\n",
    "\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433,\n",
    " fit_inverse_transform=True)\n",
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.782416297453034e-26"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(X, X_preimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLE Local linear embedding (manifold Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)\n",
    "X_reduced = lle.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
